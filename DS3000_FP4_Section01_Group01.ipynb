{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Fall 2019</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Project Title</h1> </center>\n",
    "<center><h4>Tatiana Ediger, Sidney La Fontaine, Sauharda Rajbhandari</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "Add your summary here (100-150 words)\n",
    "\n",
    "Provide a brief summary of your project. After reading this executive summary, your readers should have a rough understanding of what you did in this project. You can think of this summary in terms of the four sections of the report and write 1-2 sentences describing each section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "    I would like to address the misinformation that is spreading about how impractical wind turbines are as a legitimate energy source that the United States could rely upon. Too often in conversations about green energy sources that could significantly help ease the United States' over-reliance on fossil fuels and coal, wind energy is dismissed as not efficient enough because turbines cannot convert wind into electricity at a perfect 100 percent efficiency. Yet the amount of actual electricity a wind turbine can produce is never mentioned. I plan to use data collected about the weather in a few areas in the United States and convert it into the watts that could potentially be produced by a wind turbine in that area. I can find data on the weather across the United States from a multitude of different sources but I will most likely get data from NOAA (National Oceanic and Atmospheric Administration) about temperature, wind speed, air density, and air pressure.\n",
    "    \n",
    "Significance of the Problem:\n",
    "    This project is important because it will show how much electricity can actually be generated by wind turbines in real areas of the United States. This can be used as another piece of evidence in favor of building more wind turbines to lessen the United States’ dependence on harmful sources of electricity such as fossil fuels and coal, which wreak havoc on our atmosphere and have been a major contributing factor in global warming.\n",
    "    \n",
    "Questions:\n",
    "\tWhen we started we knew we wanted to ask questions about power produced from wind, but we did not specifically know what we wanted to ask, so below are some of the many questions we considered asking as our hypothesis, and some questions we wanted to answer separately from our hypothesis.\n",
    "    \n",
    "1.\tWould wind power be practical to power a small town?\n",
    "2.\tHow much land would it take to power a city using wind turbines, for example New York City?\n",
    "3.\tWould there be a difference in cost for a person/small business to buy, install, and maintain a wind turbine or buy electricity from an electrical company?\n",
    "4.\tWhat is the cost to carbon footprint ratio difference in using only wind turbines versus what we currently use to generate electricity?\n",
    "5.\tWhat machine learning algorithm would be most effective at predicting the weather based upon our features?\n",
    "\n",
    "Hypothesis:\n",
    "\n",
    "Null Hypothesis: \n",
    "There is no difference in amount of energy produced from wind turbines based on time of day.\n",
    "\n",
    "Alternate Hypothesis:\n",
    "There is a difference in amount of energy produced from wind turbines based on time of day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "\n",
    "We acquired our data from NOAA, the National Oceanic and Atmospheric Administration (https://www.noaa.gov/), using an api. Our final data set, both raw and wrangled are stored on the github repository for this project. \n",
    "\n",
    "**Our raw dataset,weather_data.csv, contains: **\n",
    "\n",
    "Time Period: the time the information was gathered by NOAA, in military time\n",
    "\n",
    "Location: a link to the specific station where the data was gathered by NOAA \n",
    "\n",
    "Wind Direction (degrees): the direction wind was traveling in degrees\n",
    "\n",
    "Wind Speed (m_s-1): the speed of the wind in meters per second\n",
    "\n",
    "Air Pressure: the pressure of the air in Pascals\n",
    "\n",
    "Temperature (C): the temperature in Celcius\n",
    "\n",
    "Our wrangled dataset, Transformed_csv.csv, contains:\n",
    "\n",
    "Time Period: the time the information was gathered by NOAA, in military time\n",
    "\n",
    "Wind Direction (degrees): the direction wind was traveling in degrees\n",
    "\n",
    "Wind Speed (m_s-1): the speed of the wind in meters per second\n",
    "\n",
    "Air Pressure: the pressure of the air in Pascals\n",
    "\n",
    "Temperature (K): the temperature in Kalvin\n",
    "\n",
    "Power Generated (watts): the power that would be generated by a GE 1.5s turbine, if it were at the station where the data was gathered\n",
    "\n",
    "Hour: the hour of the day the information was gathered by NOAA, in military time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noaa_sdk import noaa\n",
    "import pandas as pd\n",
    "df_weather = pd.DataFrame(columns = [\"Time Period\", \"Location\", \"Wind Direction (degrees)\", \"Wind Speed (m_s-1)\", \"Air Pressure (pa)\", \"Temperature (C)\"])\n",
    "\n",
    "# We used a NOAA API to scrape data from the NOAA website, specifcally the timestamp, station, wind direction, wind \n",
    "# speed, barometric pressure, and temperature. Then we put all of this data into a dataframe.\n",
    "n = noaa.NOAA()\n",
    "observations = n.get_observations('76006','US', start='2019-10-06',end='2019-11-22') \n",
    "for observation in observations:\n",
    "    time = observation['timestamp']\n",
    "    loc = observation['station']\n",
    "    direct = observation['windDirection']['value']\n",
    "    speed = observation['windSpeed']['value']\n",
    "    pres = observation['barometricPressure']['value']\n",
    "    temp = observation['temperature']['value']\n",
    "    \n",
    "    df_weather = df_weather.append({\"Time Period\": time, \"Location\":loc, \"Wind Direction (degrees)\":direct, \"Wind Speed (m_s-1)\": speed, \"Air Pressure (pa)\": pres, \"Temperature (C)\":temp},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "    \n",
    "print(\"Done\")\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the newly scaped data into a csv\n",
    "df_weather.to_csv(\"weather_data.csv\", index = False, mode = \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weather_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sort the dataframe with all of our scraped data\n",
    "df = df.drop_duplicates([\"Time Period\"])\n",
    "df = df.sort_values(by='Time Period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we write the sorted dataframe to the csv\n",
    "df.to_csv(\"weather_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Variables\n",
    "**Independent Variable (from wrangled dataset, Transformed_csv.csv):**\n",
    "\n",
    "Time Period: the time the information was gathered by NOAA, in military time\n",
    "\n",
    "Wind Direction (degrees): the direction wind was traveling in degrees\n",
    "\n",
    "Wind Speed (m_s-1): the speed of the wind in meters per second\n",
    "\n",
    "Air Pressure: the pressure of the air in Pascals\n",
    "\n",
    "Temperature (K): the temperature in Kalvin\n",
    "\n",
    "Hour: the hour of the day the information was gathered by NOAA, in military time\n",
    "\n",
    "**Independent Variables (from wrangled dataset, Transformed_csv.csv):**\n",
    "\n",
    "Power Generated (watts): the power that would be generated by a GE 1.5s turbine, if it were at the station where the data was gathered\n",
    "\n",
    "**Features:**\n",
    "\n",
    "Wind Direction (degrees),\n",
    "Wind Speed (m_s-1),\n",
    "Air Pressure,\n",
    "Temperature (K), and\n",
    "Hour\n",
    "\n",
    "**Target:**\n",
    "Power Generated (watts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Data Analysis\n",
    "\n",
    "   The goal of our predictive model was to predict the amount of power generated, in watts, based on our features. We choose to use supervised regression machine learning algorithms, specifically Linear Regression, Ridge, Lasso, k-Nearest Neighbor, and Support Vector Machine. We choose to use these algorithms because they were the standard regression machine learning algorithms we knew and we wanted to test all of them to see which was the most effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading in our raw csv file from Git Hub.\n",
    "url = 'https://raw.githubusercontent.com/sidneylafont/Wind-Project/master/weather_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# We dropped all columns that included any NA values.\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the temperature from Celcius to Kelvin so we can use the the temperature in our equation for\n",
    "# calculating Power Generated in watts.\n",
    "df['Temperature (C)'] = df['Temperature (C)'] + 273.15\n",
    "df['Temperature (K)'] = df['Temperature (C)']\n",
    "df = df.drop(columns=['Temperature (C)'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The equation for calculating Power Generated:\n",
    "#Power = Cp 1/2 ρ A V³\n",
    "#P = Power output, watts\n",
    "#Cp = Maximum power coefficient, ranging from 0.25 to 0.45, dimension less (theoretical maximum = 0.59)\n",
    "#ρ = Air density, kg/m³\n",
    "#A = Rotor swept area, m² or\n",
    "#π D² / 4 (D is the rotor diameter in m, π = 3.1416)\n",
    "#V = Wind speed, mps[2]\n",
    "\n",
    "# density = pressure / (temp * constant)\n",
    "\n",
    "#Our source for the equation of calculating air density, and to find the specific gas constant.\n",
    "#air density: https://www.brisbanehotairballooning.com.au/calculate-air-density/\n",
    "specific_gas_constant_for_dry_air = 287.05 # in J/(kg.K)\n",
    "\n",
    "#Our source for finding the maximum power coefficient\n",
    "#https://openei.org/wiki/Small_Wind_Guidebook/How_Much_Energy_Will_My_System_Generate\n",
    "Maximum_power_coefficient = .35\n",
    "\n",
    "#Our source for details about the rotor_swept_area for a certain wind turbine\n",
    "#all turbines: http://www.aweo.org/windmodels.html\n",
    "#we are using the wind turbine: GE 1.5s \n",
    "#GE 1.5s turbine: https://www.en.wind-turbine-models.com/turbines/565-general-electric-ge-1.5s\n",
    "Rotor_swept_area = 3904 #m^2 got \n",
    "\n",
    "#Calculates the power generated by a wind turbine with the given wind speed, air pressure and temperature.\n",
    "def calculate_power(wind_speed, air_pressure, temp):\n",
    "    air_density = air_pressure / (temp * specific_gas_constant_for_dry_air)\n",
    "    power = Maximum_power_coefficient * .5 * air_density * Rotor_swept_area * (wind_speed ** 3)\n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding another column to our data frame for the power generated.\n",
    "powers = []\n",
    "for index, row in df.iterrows():\n",
    "    powers.append(calculate_power(row['Wind Speed (m_s-1)'], row['Air Pressure (pa)'], row['Temperature (K)']))\n",
    "df['Power Generated (watts)'] = powers\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the location from our data frame.\n",
    "df = df.drop(['Location'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time\n",
    "\n",
    "# converts a given date represented as a string to the datetime data type built into python.\n",
    "def convert_to_datetime(date):\n",
    "    return datetime(int(date[0:4]), int(date[5:7]), int(date[8:10]), int(date[11:13]), int(date[14:16]))\n",
    "\n",
    "# changing the Time Period in our Data Frame from string form to datetime form.\n",
    "df['Time Period'] = df['Time Period'].apply(convert_to_datetime)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the hour from the given datetime.\n",
    "def get_hour(date):\n",
    "    return date.hour\n",
    "\n",
    "# Adds an additional column to our data frame for the hour of day at which each data collection point took place\n",
    "df['Hour'] = df['Time Period'].apply(get_hour)\n",
    "df.to_csv(\"Transformed_csv.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features and target for our data frame:\n",
    "# The features we used for our machine learning techniques later on were Hour, Wind Direction, Wind Speed, \n",
    "# Air Pressure, Temperature, and Hour. We then proceeded to carry out feature extraction and selection for these\n",
    "# variables.\n",
    "feature_hour = pd.DataFrame({'Hour': df['Hour']})\n",
    "features_weather_info = df.drop(columns=['Power Generated (watts)', 'Time Period'])\n",
    "# Our target was the Power Generated by the Wind Turbine.\n",
    "target_weather_info = df['Power Generated (watts)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used OneHotEncoder on the Hour variable to transform it into a binary transformation of a feature in a grid form.\n",
    "# This way, since the numbers get larger as you get a higher hour, which might mess up the machine learning \n",
    "# algorithm, we standardize everything to be in terms of 0's and 1's.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "enc = OneHotEncoder(sparse = False, handle_unknown='ignore')\n",
    "enc_hour = enc.fit_transform(feature_hour)\n",
    "enc_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_weather_info[\"Hour\"] = enc_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Splitting the data into it's training and testing sets (including the one-hot encoded hours)\n",
    "X_train_wi, X_test_wi, y_train_wi, y_test_wi = train_test_split(features_weather_info, target_weather_info, random_state=3000)\n",
    "\n",
    "#defined our selection method to be SelectKBest, choosing the best 3 features,\n",
    "# and we specified the score function to be f_regression. Then we fit this to our testing and training.\n",
    "select = SelectKBest(score_func=f_regression, k = 3)\n",
    "select.fit(X_train_wi, y_train_wi)\n",
    "\n",
    "#transform training and testing sets so only the selected features are retained\n",
    "X_train_selected_wi = select.transform(X_train_wi)\n",
    "X_test_selected_wi = select.transform(X_test_wi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_weather_info.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows us that when we do feature selection for features_weather_info, the selected features are:\n",
    "# Wind Direction(degrees), Wind Speed(m_s-1) and Air Pressure. \n",
    "# According to the model, Hour and Temperature matter less when trying to predict.\n",
    "select.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/sidneylafont/Wind-Project/master/Transformed_csv.csv'\n",
    "df2 = pd.read_csv(url)\n",
    "df2 = df2.dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Hour of the day vs. Power generated in watts.\n",
    "import plotly.express as px\n",
    "fig = px.bar(df2, x=\"Hour\", y=\"Power Generated (watts)\", \n",
    "              title='Power Generated in watts per Hour of Day', template=\"none\")\n",
    "fig.show()\n",
    "\n",
    "# This graph shows us that there appear to be peak times of the day where more power is generated, in particular\n",
    "# there appears to be peaks around 5 AM and 6 PM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Wind Speed vs. Power Generated.\n",
    "fig = px.scatter(df2, x=\"Wind Speed (m_s-1)\", y=\"Power Generated (watts)\",\n",
    "                    title='Relationship between Power Generated from Wind Turbine (watts) and Wind Speed')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# This plot shows us that there appears to be a positive correlation between the power generated from the wind turbine\n",
    "# and the wind speed from the area. As the wind speed increases, the power generated appears to as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Wind Direction vs. Power Generated.\n",
    "fig = px.scatter(df2, x=\"Wind Direction (degrees)\", y=\"Power Generated (watts)\",\n",
    "                title='Relationship between Power Generated from Wind Turbine (watts) and Wind Direction')\n",
    "fig.show()\n",
    "\n",
    "# This plot shows us that there appear to be certain peak directions which increases the power generated,\n",
    "# at around 20, 180 and 320 degrees. There also appears to be a very slight positive correlation between the two,\n",
    "# although it is slightly skewed by the different peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Temperature vs. Power Generated.\n",
    "fig = px.scatter(df2, x=\"Temperature (K)\", y=\"Power Generated (watts)\",\n",
    "                 title='Relationship between Power Generated from Wind Turbine (watts) and Temperature')\n",
    "fig.show()\n",
    "\n",
    "# This plot shows us that there appears to be very little correlation or trends between the temperature and power\n",
    "# generated. The data appears to be scattered about in no consistent fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Air Pressure vs. Power Generated.\n",
    "fig = px.scatter(df2, x=\"Air Pressure (pa)\", y=\"Power Generated (watts)\",\n",
    "                title='Relationship between Power Generated from Wind Turbine (watts) and Air Pressure')\n",
    "fig.show()\n",
    "\n",
    "# This plot shows us that there also appears to be very little correlation or trends between the air pressure \n",
    "# and power generated. There is arguably a very slight positive correlation between the two, but in general\n",
    "# the data seems to be scattered throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : LINKS TO OUR GRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above in section 3.1, where we do feature selection, we split our data into it's respective training, \n",
    "# testing and validation sets since we wanted to use our selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting our Hypothesis Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Retrieving our webscraped and transformed data, which is stored in Sidney's GitHub repository\n",
    "url = 'https://raw.githubusercontent.com/sidneylafont/Wind-Project/master/Transformed_csv.csv'\n",
    "df = pd.read_csv(url)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_anova = df2\n",
    "\n",
    "# Grouping the data into four categories: \"early morning\", \"mid morning\", \"afternoon\", and \"night\" based on the \n",
    "# time of day that the data was collected. This is for the purposes of conducting the ANOVA test to test our hypothesis.\n",
    "def categorize_hour(hour):\n",
    "    if (hour >= 0 and hour < 6):\n",
    "        return \"early morning\"\n",
    "    elif (hour >= 6 and hour < 12):\n",
    "        return \"mid morning\"\n",
    "    elif (hour >= 12 and hour < 18):\n",
    "        return \"afternoon\"\n",
    "    else:\n",
    "        return \"night\"\n",
    "\n",
    "# Modifying the dataframe to hold just the power generated and the categorized time period in which the data was collected.\n",
    "df_for_anova[\"Categorized Hours\"] = df_for_anova[\"Hour\"].apply(categorize_hour)\n",
    "df_for_anova = df_for_anova.drop(columns = [\"Time Period\", \"Wind Direction (degrees)\", \"Wind Speed (m_s-1)\", \"Air Pressure (pa)\", \"Temperature (K)\", \"Hour\"])\n",
    "df_for_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using descriptive statistics to analyze the grouped dataframe\n",
    "describe = df_for_anova.groupby(\"Categorized Hours\").agg([\"count\", \"mean\", \"std\", \"sem\"])\n",
    "describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe = describe[\"Power Generated (watts)\"]\n",
    "describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the index of the data frame and uses the default one\n",
    "describe.reset_index(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as plt\n",
    "\n",
    "# Visualizing the data in a bar graph\n",
    "graph = plt.bar(describe, x = \"Categorized Hours\", y = \"mean\", error_x = \"sem\", error_y = \"sem\", template='seaborn', width=500, \n",
    "                labels = {\"mean\": \"Power Generated\", \"Group\":\"Categorized Hours\"})\n",
    "\n",
    "graph.update_traces(marker_color=[\"#d3d3d3\", \"#FFF\", \"#FFF\"])\n",
    "graph.update_traces(marker= dict(line={\"width\":3,\"color\":\"#000000\"}))\n",
    "\n",
    "graph.update_xaxes(title_font={\"size\":16}, tickfont = {\"size\":14, \"color\":\"gray\"})\n",
    "graph.update_yaxes(title_font={\"size\":16}, tickfont = {\"size\":14, \"color\":\"gray\"})\n",
    "\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Creating series objects for each of the four categories we have.\n",
    "early_morning = df_for_anova[df_for_anova[\"Categorized Hours\"] == \"early morning\"][\"Power Generated (watts)\"]\n",
    "mid_morning = df_for_anova[df_for_anova[\"Categorized Hours\"] == \"mid morning\"][\"Power Generated (watts)\"]\n",
    "afternoon = df_for_anova[df_for_anova[\"Categorized Hours\"] == \"afternoon\"][\"Power Generated (watts)\"]\n",
    "night = df_for_anova[df_for_anova[\"Categorized Hours\"] == \"night\"][\"Power Generated (watts)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting the one way ANOVA test:\n",
    "results = stats.f_oneway(early_morning, mid_morning, afternoon, night)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the t-value\n",
    "fstatistic = results[0]\n",
    "fstatistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the p-value\n",
    "pvalue = results[1]\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a one way ANOVA test, we have to calculate two degrees of freedom values.\n",
    "# The first degree of freedom (the number of groups being compared - 1)\n",
    "df1 = len(describe) - 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second degree of freedom calculated.\n",
    "df2 = (len(early_morning) - 1) + (len(mid_morning) - 1) + (len(afternoon) - 1) + (len(night) - 1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "def oneway_ANOVA(data, IV, DV):\n",
    "    \n",
    "    mc = MultiComparison(data[DV], data[IV])\n",
    "    print(\"-----------------------\")\n",
    "    print(\"ONE-WAY ANOVA RESULTS\")\n",
    "    print(\"-----------------------\\n\\n\")\n",
    "    print(\"F-test\")\n",
    "    print(\"-------\\n\")\n",
    "    f_oneway_results = stats.f_oneway(early_morning, mid_morning, afternoon, night)\n",
    "    print(\"F(2, 33) = \" + str(round(f_oneway_results[0], 2)) + \", p = \" + str(round(f_oneway_results[1], 4)) + \"\\n\\n\")\n",
    "    print(\"Assumption Checks\")\n",
    "    print(\"-------------------\\n\")\n",
    "    print(\"Assumption of Equality of Variances:\")\n",
    "    levene_results = stats.levene(early_morning, mid_morning, afternoon, night)\n",
    "    print(\"\\t\" + str(levene_results))\n",
    "    if (levene_results[1] < 0.05):\n",
    "        print(\"\\tAssumption is violated. p < .05\\n\")\n",
    "    else:\n",
    "        print(\"\\tAssumption is met. p > .05\\n\")\n",
    "        \n",
    "    print(\"Assumption of Normality:\\n\")\n",
    "    \n",
    "    shapiro_early = stats.shapiro(early_morning)\n",
    "    print(\"\\tEarly Morning : \" + str(shapiro_early))\n",
    "    if (shapiro_early[1] < 0.05):\n",
    "        print(\"\\t\\tAssumption is violated. p < .05\\n\")\n",
    "    else:\n",
    "        print(\"\\t\\tAssumption is met. p > .05\\n\")\n",
    "        \n",
    "    shapiro_mid = stats.shapiro(mid_morning)\n",
    "    print(\"\\tMid Morning : \" + str(shapiro_mid))\n",
    "    if (shapiro_mid[1] < 0.05):\n",
    "        print(\"\\t\\tAssumption is violated. p < .05\\n\")\n",
    "    else:\n",
    "        print(\"\\t\\tAssumption is met. p > .05\\n\")\n",
    "    \n",
    "    shapiro_aft = stats.shapiro(afternoon)\n",
    "    print(\"\\tAfternoon : \" + str(shapiro_aft))\n",
    "    if (shapiro_aft[1] < 0.05):\n",
    "        print(\"\\t\\tAssumption is violated. p < .05\\n\")\n",
    "    else:\n",
    "        print(\"\\t\\tAssumption is met. p > .05\\n\")\n",
    "        \n",
    "    shapiro_night = stats.shapiro(night)\n",
    "    print(\"\\tNight : \" + str(shapiro_night))\n",
    "    if (shapiro_night[1] < 0.05):\n",
    "        print(\"\\t\\tAssumption is violated. p < .05\\n\")\n",
    "    else:\n",
    "        print(\"\\t\\tAssumption is met. p > .05\\n\")\n",
    "        \n",
    "        \n",
    "    print(\"Post-hoc Tests\")\n",
    "    print(\"----------------\\n\")\n",
    "    print(str(mc.tukeyhsd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneway_ANOVA(df_for_anova, \"Categorized Hours\", \"Power Generated (watts)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERPRETATION in general of overall F-test results.\n",
    "\n",
    "# H0: There is no correlation between period of the day and the amount of power generated.\n",
    "# H1: There is a correlation between period of the day and the amount of power generated.\n",
    "# Doing an ANOVA test at a 5% significance level:\n",
    "\n",
    "# Since the results of our ANOVA was a p-value of 5.216531365742044e-10 which is less than our significance value (0.05),\n",
    "# we have enough evidence to reject our null hypothesis, and support the claim that there is a relationship between\n",
    "# the period of the day and power generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Results and Interpretation of follow up Tests:\n",
    "\n",
    "# The results of the general F-test show that there is a significant difference between sample means. \n",
    "# This shows that there is an overall significant effect of the type of search design on task completion time. \n",
    "# A p-value of nearly zero means that the probability of the results happening based on chance are so slim assuming \n",
    "# the null hypothesis is true.\n",
    "\n",
    "# Unfortunately, the assumption check for the equality of variance tell us that the variances are not all roughly \n",
    "# equal. This means that technically doing a one-way ANOVA is not the best measure for comparing the results of \n",
    "# our variables.\n",
    "\n",
    "# The assumption check for normality tells us that none of the results for time period of the day are \n",
    "# approximately normally distributed. \n",
    "\n",
    "# The results of the post-hoc tests allow us to compare all the different designs to one another in groups of \n",
    "# two instead of overall. We see that between afternoon and early morning, afternoon and mid-morning, and early\n",
    "# morning and mid-morning we fail to reject the mean, which tells us that there is no significant difference\n",
    "# between the results of the two. However with respect to afternoon vs night, early-morning vs night and mid-morning \n",
    "# vs night, there is enough evidence to reject the mean, meaning that there is a significant difference between all\n",
    "# these pairs. Since there is a positive mean difference between (night - afternoon), (night - earlymorning), and \n",
    "# (night - midmorning), we have evidence to support that there is more power generated at night. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning for weather info & for hour\n",
    "\n",
    "# For Weather Info features:\n",
    "\n",
    "# import statements\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# The 5 regression estimators we will be using: Linear Regression, Ridge, Lasso, K-Nearest Neighbhors,\n",
    "# and Support Vector Machine\n",
    "estimators = {'Linear Regression':LinearRegression(), 'Ridge':Ridge(), \n",
    "              'Lasso':Lasso(), 'k-Nearest Neighbor':KNeighborsRegressor(), 'Support Vector Machine':SVR(gamma=\"scale\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Returns a list of the fitted models and prints out to R-squared values for the training and testing sets.\n",
    "def regressors_percentage_split():\n",
    "    model_list = []\n",
    "    for key, value in estimators.items():\n",
    "        \n",
    "        model = value.fit(X=X_train_selected_wi, y=y_train_wi)\n",
    "        model_list.append(model)\n",
    "        \n",
    "        print(key,\":\")\n",
    "        print(\"\\tR-squared value for training set: \", r2_score(y_train_wi, model.predict(X_train_selected_wi)))\n",
    "        print(\"\\tR-squared value for testing set: \", r2_score(y_test_wi, model.predict(X_test_selected_wi)), \"\\n\")\n",
    "        \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : LINKS TO OUR GRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Model Evaluation\n",
    "* Evaluate the performance of your algorithms on appropriate evaluation metrics, using your validation set\n",
    "* Interpret your results from multiple models (and hypothesis tests, if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We trained our data in the declaration of the method: regressors_percentage_split() above, and our results here\n",
    "# show our evaluated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = regressors_percentage_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a list of what we predict from each model.\n",
    "predicted_list = []\n",
    "\n",
    "# Iterating through the models and appending its predicted result to the list above.\n",
    "for model in model_list:\n",
    "    predicted_list.append(model.predict(X_test_selected_wi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = y_test_wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of the models' names for convenience.\n",
    "model_name = [\"Linear Regression\", \"Ridge\", \"Lasso\", \"K-nearest Neighbhor\", \"SVM\"]\n",
    "\n",
    "# Comparing what was predicted and what was expected from the five machine learning algorithms on our first \n",
    "# 5 data points.\n",
    "for i in range(len(predicted_list)) : \n",
    "    print(model_name[i]+\":\")\n",
    "    for p, e in zip(predicted_list[i][:5], expected[:5]):\n",
    "        print(f'\\tpredicted: {p:.2f}, expected: {e:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A different data frame for each machine learning algorithm and what it expected the result to be.\n",
    "results_df_lr = pd.DataFrame(expected.values, columns=[\"expected\"])\n",
    "results_df_ridge = pd.DataFrame(expected.values, columns=[\"expected\"])\n",
    "results_df_lasso = pd.DataFrame(expected.values, columns=[\"expected\"])\n",
    "results_df_knn = pd.DataFrame(expected.values, columns=[\"expected\"])\n",
    "results_df_svm = pd.DataFrame(expected.values, columns=[\"expected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column on the data frame with the data that the respective machine learning model predicted.\n",
    "results_df_lr[\"predicted\"] = predicted_list[0]\n",
    "results_df_ridge[\"predicted\"] = predicted_list[1]\n",
    "results_df_lasso[\"predicted\"] = predicted_list[2]\n",
    "results_df_knn[\"predicted\"] = predicted_list[3]\n",
    "results_df_svm[\"predicted\"] = predicted_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#produce the scatter plot using the linear regression algorithm\n",
    "graph = px.scatter(results_df_lr, x=\"expected\", y=\"predicted\", template=\"none\", color=\"predicted\", opacity=.7)\n",
    "\n",
    "#Add the \"perfect prediction\" line; this is not the regression line\n",
    "graph.update_layout(\n",
    "    shapes=[    \n",
    "        go.layout.Shape(\n",
    "            type=\"line\",\n",
    "            x0=0, y0=0,\n",
    "            x1=800000, y1=300000,\n",
    "            line=dict(color=\"coral\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#produce the scatter plot\n",
    "graph = px.scatter(results_df_ridge, x=\"expected\", y=\"predicted\", template=\"none\", color=\"predicted\", opacity=.7)\n",
    "\n",
    "#Add the \"perfect prediction\" line; this is not the regression line\n",
    "graph.update_layout(\n",
    "    \n",
    "    shapes=[    \n",
    "        go.layout.Shape(\n",
    "            type=\"line\",\n",
    "            x0=0, y0=0,\n",
    "            x1=800000, y1=300000,\n",
    "            line=dict(color=\"coral\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#produce the scatter plot\n",
    "graph = px.scatter(results_df_lasso, x=\"expected\", y=\"predicted\", template=\"none\", color=\"predicted\", opacity=.7)\n",
    "\n",
    "#Add the \"perfect prediction\" line; this is not the regression line\n",
    "graph.update_layout(\n",
    "    \n",
    "    shapes=[    \n",
    "        go.layout.Shape(\n",
    "            type=\"line\",\n",
    "            x0=0, y0=0,\n",
    "            x1=800000, y1=300000,\n",
    "            line=dict(color=\"coral\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#produce the scatter plot\n",
    "graph = px.scatter(results_df_knn, x=\"expected\", y=\"predicted\", template=\"none\", color=\"predicted\", opacity=.7)\n",
    "\n",
    "#Add the \"perfect prediction\" line; this is not the regression line\n",
    "graph.update_layout(\n",
    "    \n",
    "    shapes=[    \n",
    "        go.layout.Shape(\n",
    "            type=\"line\",\n",
    "            x0=0, y0=0,\n",
    "            x1=800000, y1=300000,\n",
    "            line=dict(color=\"coral\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#produce the scatter plot\n",
    "graph = px.scatter(results_df_svm, x=\"expected\", y=\"predicted\", template=\"none\", color=\"predicted\", opacity=.7)\n",
    "\n",
    "#Add the \"perfect prediction\" line; this is not the regression line\n",
    "graph.update_layout(\n",
    "    \n",
    "    shapes=[    \n",
    "        go.layout.Shape(\n",
    "            type=\"line\",\n",
    "            x0=0, y0=0,\n",
    "            x1=800000, y1=300000,\n",
    "            line=dict(color=\"coral\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#produce the scatter plot\n",
    "graph = px.scatter(results_df_svm, x=\"expected\", y=\"predicted\", template=\"none\", color=\"predicted\", opacity=.7)\n",
    "\n",
    "#Add the \"perfect prediction\" line; this is not the regression line\n",
    "graph.update_layout(\n",
    "    \n",
    "    shapes=[    \n",
    "        go.layout.Shape(\n",
    "            type=\"line\",\n",
    "            x0=0, y0=0,\n",
    "            x1=800000, y1=300000,\n",
    "            line=dict(color=\"coral\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : LINKS TO OUR GRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Optimization\n",
    "* Tune your models using appropriate hyperparameters\n",
    "* Explain why you are doing this (e.g., to avoid overfitting, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Optimization:\n",
    "\n",
    "# We tuned our models to avoid overfitting. We did this for both the KNN and SVR models.\n",
    "# To tune our KNN model, we adjusted the hyperparameters of possible number of neighbors and the ways the distance\n",
    "# is calculated.\n",
    "# To tune our SVR model, we adjusted the regularization parameter.\n",
    "\n",
    "# The parameter grid used to optimize/tune the KNN model.\n",
    "# n_neighbhors is a list of the possible number of neighbhors\n",
    "# metric is a list of the ways that the distance is calculated\n",
    "param_grid = {\"n_neighbors\":[1, 5, 10, 100, 1000], \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Utilizing grid search for K-Nearest Neighbhors model\n",
    "def grid_search_kNN():\n",
    "    # Initializing the grid search model\n",
    "    grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5)\n",
    "    # Fitting the grid search model with our data\n",
    "    grid_search.fit(X=X_train_selected_wi, y=y_train_wi)\n",
    "\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Training set score with best parameters: \", grid_search.best_score_)\n",
    "    print(\"Test set score with best parameters: \", grid_search.score(X_test_selected_wi, y_test_wi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter grid for the SVR model\n",
    "param_grid_svr = {\"C\":[0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Utilizing grid search to optimize the SVR model\n",
    "def grid_search_SVR():\n",
    "    # Initializing the grid search model\n",
    "    grid_search = GridSearchCV(SVR(gamma='scale'), param_grid_svr, cv=5)\n",
    "    # Fitting the grid search model with our data\n",
    "    grid_search.fit(X=X_train_selected_wi, y=y_train_wi)\n",
    "\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Training set score with best parameters: \", grid_search.best_score_)\n",
    "    print(\"Test set score with best parameters: \", grid_search.score(X_test_selected_wi, y_test_wi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Model Testing\n",
    "* Test your tuned algorithms using your testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In section 3.5, we declared methods where we initialized the Grid Search model, and fit it to our data,\n",
    "# so in this section we show the results of testing our tuned algorithms using our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Grid Search to our data using KNeighborsRegressor and showing test results.\n",
    "grid_search_kNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Grid Search to our data using SVR and showing test results.\n",
    "grid_search_SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION\n",
    "We utilized 5 machine learning regression algorithms to analyze our data. The first step was to derive the r-squared value for both training and testing sets without altering our models at all. Then, we created dataframes of each model's predicted and expected data, which we graphed and compared to the \"perfect prediction\" line.\n",
    "\n",
    "The regression algorithms we used were: Linear Regression, Ridge, Lasso, K-Nearest Neighbhors, and Support Vector Model (SVM). After running these algorithms, we determined that the Linear Regression, Ridge, and Lasso algorithms revealed the best performance and those are the ones that should be used for our predictive model.\n",
    "\n",
    "For our hypothesis tests, we were testing to see whether or not there was a relationship between period of day and time generated. Since the results of our ANOVA was a p-value of 5.216531365742044e-10 which is less than our significance value (0.05), we have enough evidence to reject our null hypothesis, and support the claim that there is a relationship between the period of the day and power generated. With respect to the overall results of our ANOVA test and it's follow up tests, the results of the general F-test show that there is a significant difference between sample means. This shows that there is an overall significant effect of the type of search design on task completion time. A p-value of nearly zero means that the probability of the results happening based on chance are so slim assuming the null hypothesis is true. Unfortunately, the assumption check for the equality of variance tell us that the variances are not all roughly equal. This means that technically doing a one-way ANOVA is not the best measure for comparing the results of our variables. The assumption check for normality tells us that none of the results for time period of the day are approximately normally distributed. The results of the post-hoc tests allow us to compare all the different designs to one another in groups of two instead of overall. We see that between afternoon and early morning, afternoon and mid-morning, and early morning and mid-morning we fail to reject the mean, which tells us that there is no significant difference between the results of the two. However with respect to afternoon vs night, early-morning vs night and mid-morning vs night, there is enough evidence to reject the mean, meaning that there is a significant difference between all these pairs. Since there is a positive mean difference between (night - afternoon), (night - earlymorning), and (night - midmorning), we have evidence to support that there is more power generated at night. \n",
    "\n",
    "For future work we would make sure to have a thorough understanding of what question we want to answer and what methods, such as machine learning, t-tests, etc., we would use to answer those questions before we start scraping data. Also, we would have scraped more features for our dataset so that we could have as much information as possible for our dataset. After observing the results from our ANOVA test and seeing that our none of our results for time period of the day are approximately normally distributed, and our variances weren't all approximately equal, we could do some other forms of hypothesis testing in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n",
    "\n",
    "Sidney La Fontaine wrote the web scraping script. Tatiana Ediger wrote the data visualization scripts. Sauharda Rajbhandari wrote the feature engineering script. The rest of the project was written by all of us, peer programing, so that all of us were able to learn from and be knowledgable about our entire project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
